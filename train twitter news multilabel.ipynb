{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data processsing\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "############################# \n",
    "############ file path\n",
    "filepath = \"twitter.json\"\n",
    "filepath2 = \"twits_raw_20180725.json\"\n",
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_multiple(segments):\n",
    "    chunk = \"\"\n",
    "    news_list = []\n",
    "    for segment in segments:\n",
    "        chunk += segment\n",
    "        try:\n",
    "            yield json.loads(chunk)\n",
    "            chunk = \"\"\n",
    "        except ValueError:\n",
    "            pass\n",
    "def get_news_list(path):\n",
    "    news_list = []\n",
    "    with open(path) as f:\n",
    "        for parsed_json in load_json_multiple(f):\n",
    "            news_list.append(parsed_json)\n",
    "    return news_list\n",
    "def get_tag_list(twit_list):\n",
    "    tag_list = []\n",
    "    for twit in twit_list:\n",
    "        for tag in twit['tags']:\n",
    "            if tag not in tag_list and tag != 'NONE':\n",
    "                tag_list.append(tag)\n",
    "    return tag_list\n",
    "def get_tagged_new_list(path):\n",
    "    twit_list = get_news_list(path)\n",
    "    tag_list = get_tag_list(twit_list)\n",
    "\n",
    "    news_list_G9 = [ item for item in twit_list \n",
    "                    if bool(set(tag_list) & set(item['tags']))]\n",
    "\n",
    "    news_list_none = [item for item in twit_list if item['tags'] == ['NONE']]\n",
    "    return news_list_G9, news_list_none\n",
    "\n",
    "tagged_news, none_tagged_news = get_tagged_new_list(filepath)\n",
    "tagged_news2, none_tagged_news2 = get_tagged_new_list(filepath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66449\n",
      "[['JPY', 'EUR'], ['AUD', 'USD'], ['USD'], ['USD'], ['EUR', 'GBP'], ['AUD', 'EUR'], ['USD'], ['USD', 'CNY'], ['USD', 'CNY'], ['USD', 'CAD']]\n",
      "[[0 0 0 0 1 0 1 0 0]\n",
      " [1 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 1 0 0 0]\n",
      " [1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 1]]\n",
      "[80, 257, 256, 256, 48, 17, 256, 264, 264, 258]\n"
     ]
    }
   ],
   "source": [
    "sample_twits_list = tagged_news2.copy()\n",
    "random.shuffle(sample_twits_list)\n",
    "X = [\"author: \" + twit[\"author\"] +\" \\n \" + twit['text'] for twit in sample_twits_list]\n",
    "y_raw = [twit[\"tags\"] for twit in sample_twits_list]\n",
    "mb = MultiLabelBinarizer()\n",
    "y=mb.fit_transform(y_raw)\n",
    "\n",
    "print(len(y_raw))\n",
    "print(y_raw[0:10])\n",
    "print(y[0:10])\n",
    "\n",
    "def bin2dec(bin_list):\n",
    "    int_num = 0\n",
    "    for i, digit in enumerate(bin_list):\n",
    "        int_num = int_num + digit*(2**i)\n",
    "    return int_num\n",
    "\n",
    "y_int = []\n",
    "for item in y:\n",
    "    y_int.append(bin2dec(item))\n",
    "print(y_int[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n",
      "122\n",
      "0\n",
      "69\n",
      "61466 61466\n"
     ]
    }
   ],
   "source": [
    "num_test = int(0.075*len(X))\n",
    "num_val = 0\n",
    "X_train = X[num_test:]\n",
    "X_val = X[:num_val]\n",
    "X_test = X[num_val:num_val+num_test]\n",
    "# y_train = y[:num_train]\n",
    "# y_test = y[num_train:]\n",
    "y_train = y_int[num_test:]\n",
    "y_val = y_int[:num_val]\n",
    "y_test = y_int[num_val:num_val+num_test]\n",
    "\n",
    "print(len(set(y_int)))\n",
    "print(len(set(y_train)))\n",
    "print(len(set(y_val)))\n",
    "print(len(set(y_test)))\n",
    "print(len(X_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66449"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgbm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "0.9602649006622517\n",
      "Start completes... 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# lightgbm\n",
    "t = time.time()\n",
    "static_params = {\n",
    "                    'n_estimators': 100,\n",
    "                    'task': 'train',\n",
    "                    'boosting_type': 'gbrt',\n",
    "                    'objective': 'multiclass',\n",
    "                    'metric': 'multi_logloss',\n",
    "                    'learning_rate': 0.05,\n",
    "                    'num_leaves': 31, \n",
    "                    'n_jobs': 4, \n",
    "                    'reg_alpha': 0.025,\n",
    "#                     'num_iterations': 200,\n",
    "#                     'max_bin': 62\n",
    "                }\n",
    "print('Start training...')\n",
    "# Training Support Vector Machines - SVM and calculating its performance\n",
    "text_clf_lgbm = Pipeline([('vect', CountVectorizer()), \n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('lgbm', lgbm.LGBMClassifier(\n",
    "                             **static_params\n",
    "                         ))\n",
    "                       ])\n",
    "text_clf_lgbm = text_clf_lgbm.fit(X_train, y_train)\n",
    "\n",
    "import pickle\n",
    "filename = 'multilabel_model_20180725.sav'\n",
    "pickle.dump(text_clf_lgbm, open(filename, 'wb'))\n",
    "score = text_clf_lgbm.score(X_test, y_test)\n",
    "print(score)\n",
    "print('Start completes...', (time.time() - t)//60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "text_clf_rf = Pipeline([('vect', CountVectorizer()), \n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('rf', RandomForestClassifier(n_estimators=100, random_state=42, max_depth=90))])\n",
    "text_clf_rf = text_clf_rf.fit(X_train, y_train)\n",
    "predicted_rf = text_clf_rf.predict(X_test)\n",
    "score = text_clf_rf.score(X_test, y_test)\n",
    "print(score)\n",
    "filename = 'model/multilabel_model_rf_20180725.sav'\n",
    "pickle.dump(text_clf_rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "text_clf_rf = Pipeline([('vect', CountVectorizer()), \n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('mlp', MLPClassifier(max_iter = 1, early_stopping=True, random_state=42))])\n",
    "text_clf_rf = text_clf_rf.fit(X_train, y_train)\n",
    "predicted_rf = text_clf_rf.predict(X_test)\n",
    "filename = 'model/multilabel_model_mlp_20180725.sav'\n",
    "pickle.dump(text_clf_rf, open(filename, 'wb'))\n",
    "score = text_clf_rf.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time is  7.0\n",
      "0.9634758177804535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "## voting\n",
    "t = time.time()\n",
    "static_params = {\n",
    "                    'n_estimators': 100,\n",
    "                    'task': 'train',\n",
    "                    'boosting_type': 'gbrt',\n",
    "                    'objective': 'multiclass',\n",
    "                    'metric': 'multi_logloss',\n",
    "                    'learning_rate': 0.05,\n",
    "                    'num_leaves': 31, \n",
    "                    'n_jobs': 4, \n",
    "                    'reg_alpha': 0.075,\n",
    "#                     'num_iterations': 200,\n",
    "#                     'max_bin': 62\n",
    "                }\n",
    "\n",
    "mlp_clf = MLPClassifier(max_iter = 5, early_stopping = True, random_state = 42)\n",
    "# rf_clf = RandomForestClassifier(n_estimators = 100, random_state = 42, max_depth = 90)\n",
    "lgbm_clf = lgbm.LGBMClassifier(**static_params)\n",
    "# v_clf = VotingClassifier(estimators=[('mlp', mlp_clf), ('rf', rf_clf), ('lgbm', lgbm_clf)], voting='soft')\n",
    "text_clf_pl = Pipeline([\n",
    "                         ('vect', CountVectorizer()), \n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('v_clf',  VotingClassifier(\n",
    "                             estimators=[('mlp', mlp_clf), ('lgbm', lgbm_clf)], \n",
    "                             voting='soft', weights=[2,14]))\n",
    "                       ])\n",
    "text_clf_pl = text_clf_pl.fit(X_train, y_train)\n",
    "print(\"training time is \", (time.time()-t)//60)\n",
    "filename = 'multilabel_model_vote_20180725.sav'\n",
    "pickle.dump(text_clf_pl, open(filename, 'wb'))\n",
    "score = text_clf_pl.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9624724061810155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "score = text_clf_pl.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## make the results back to binary\n",
    "y_pred = predicted_rf\n",
    "def dec2bin(num_list):\n",
    "    bin_list = []\n",
    "    for int_num in num_list:\n",
    "        bin_sub_list = []\n",
    "        for i in range(9):\n",
    "    #         print(int_num)\n",
    "            digit = int_num % 2\n",
    "            int_num = int(int_num//2)\n",
    "            bin_sub_list.append(digit)\n",
    "        bin_list.append(bin_sub_list)\n",
    "    return bin_list\n",
    "data_ = {'twit': X_test, \n",
    "         'label': mb.inverse_transform(np.asarray(dec2bin(y_test))),\n",
    "         'label_pred': mb.inverse_transform(np.asarray(dec2bin(y_pred))),\n",
    "         'correct': y_pred == y_test}\n",
    "df = pd.DataFrame(data=data_)\n",
    "df.head()\n",
    "df.to_csv('data/results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
